close all
clear
clc

load('../data/SaoPaulo_classification.mat')

%% Separe X_train in train and test to make cross-validation
[ XTr, XTe, yTr, yTe ] = divideDataSet( X_train, y_train, 4, 2 );

%% Preprocessing the data
XNormalised = normalise(X_train);
yNormalised = y_train;
yNormalised(yNormalised < 0) = 0;

%% Remove outliers
%[XFiltered, yFiltered] = removeOutlierLines(XNormalised, yNormalised, 3, 2); 
% XFiltered = fixOutliers(XNormalised, 3);
XFiltered = XNormalised;
yFiltered = yNormalised;

len = length(XFiltered);
width = size(XFiltered, 2);

%% Remove correlated columns using PCA
% XKept = pca(XFiltered, 1);
XKept = XFiltered;

%% Train
tX = [ones(length(train), 1)  XTr];
y = yTr;

% beta = logisticRegression(y, tX, 0.001);
beta = penLogisticRegression(y, tX, 0.001,1);
% beta = leastSquaresGD(y, tX, 0.01);
% beta = leastSquares(y, tX);
% re = ridgeRegression(y, tX, 10);

y_pred = sigma([ones(testSize , 1) XTe] * beta);
y_pred(y_pred >= -0.5) = 1;
y_pred(y_pred < 0.5) = 0;
y_true = yFiltered((trainSize + 1):end, :);

yPredFinal = y_pred;
yPredFinal(yPredFinal == 0) = -1; 

plot(y_true, y_pred, '*');
hold on;
max = ceil(max([y_pred y_true]));
min = floor(min([y_pred y_true]));
plot(min:max, min:max);